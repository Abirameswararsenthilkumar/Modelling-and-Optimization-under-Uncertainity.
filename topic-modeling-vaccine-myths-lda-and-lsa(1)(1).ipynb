{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-08-20T21:15:46.179939Z",
     "iopub.status.busy": "2022-08-20T21:15:46.179175Z",
     "iopub.status.idle": "2022-08-20T21:15:46.199255Z",
     "shell.execute_reply": "2022-08-20T21:15:46.198265Z",
     "shell.execute_reply.started": "2022-08-20T21:15:46.179837Z"
    }
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-20T21:15:47.845406Z",
     "iopub.status.busy": "2022-08-20T21:15:47.844688Z",
     "iopub.status.idle": "2022-08-20T21:15:48.859900Z",
     "shell.execute_reply": "2022-08-20T21:15:48.858381Z",
     "shell.execute_reply.started": "2022-08-20T21:15:47.845367Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-20T21:16:45.581435Z",
     "iopub.status.busy": "2022-08-20T21:16:45.580830Z",
     "iopub.status.idle": "2022-08-20T21:16:45.677444Z",
     "shell.execute_reply": "2022-08-20T21:16:45.676233Z",
     "shell.execute_reply.started": "2022-08-20T21:16:45.581388Z"
    }
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('../input/reddit-vaccine-myths/reddit_vm.csv', error_bad_lines=False);\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-20T21:16:46.855187Z",
     "iopub.status.busy": "2022-08-20T21:16:46.854625Z",
     "iopub.status.idle": "2022-08-20T21:16:46.861458Z",
     "shell.execute_reply": "2022-08-20T21:16:46.860480Z",
     "shell.execute_reply.started": "2022-08-20T21:16:46.855149Z"
    }
   },
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-20T21:16:47.419174Z",
     "iopub.status.busy": "2022-08-20T21:16:47.418797Z",
     "iopub.status.idle": "2022-08-20T21:16:48.980128Z",
     "shell.execute_reply": "2022-08-20T21:16:48.979236Z",
     "shell.execute_reply.started": "2022-08-20T21:16:47.419141Z"
    }
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "import string\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "import ast\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.mlab as mlab\n",
    "import seaborn as sb\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from textblob import TextBlob\n",
    "import scipy.stats as stats\n",
    "\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "from bokeh.plotting import figure, output_file, show\n",
    "from bokeh.models import Label\n",
    "from bokeh.io import output_notebook\n",
    "output_notebook()\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the data its clear thast many posts have thier body missing, lets try to find out which all data are missing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Preprocessing\n",
    "1. Tokenizing : the sentences are splint into words.\n",
    "2. Stop word are removed\n",
    "3. Lemmatization : past and future tenses are changed to present \n",
    "4. Stemming : words are reduced into their root form\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Impoting necessary libaries for topic modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-20T21:16:49.375116Z",
     "iopub.status.busy": "2022-08-20T21:16:49.374561Z",
     "iopub.status.idle": "2022-08-20T21:16:50.019410Z",
     "shell.execute_reply": "2022-08-20T21:16:50.017895Z",
     "shell.execute_reply.started": "2022-08-20T21:16:49.375077Z"
    }
   },
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "from nltk.stem import WordNetLemmatizer, SnowballStemmer\n",
    "from nltk.stem.porter import *\n",
    "import numpy as np\n",
    "np.random.seed(2018)\n",
    "import nltk\n",
    "from nltk import word_tokenize, pos_tag\n",
    "\n",
    "nltk.download('wordnet')\n",
    "stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-20T21:16:50.022016Z",
     "iopub.status.busy": "2022-08-20T21:16:50.021536Z",
     "iopub.status.idle": "2022-08-20T21:16:50.032955Z",
     "shell.execute_reply": "2022-08-20T21:16:50.031531Z",
     "shell.execute_reply.started": "2022-08-20T21:16:50.021964Z"
    }
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet\n",
    "\n",
    "def get_wordnet_pos(treebank_tag):\n",
    "\n",
    "    if treebank_tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif treebank_tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif treebank_tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif treebank_tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return wordnet.NOUN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-20T21:16:50.320472Z",
     "iopub.status.busy": "2022-08-20T21:16:50.320069Z",
     "iopub.status.idle": "2022-08-20T21:16:50.327242Z",
     "shell.execute_reply": "2022-08-20T21:16:50.326411Z",
     "shell.execute_reply.started": "2022-08-20T21:16:50.320438Z"
    }
   },
   "outputs": [],
   "source": [
    "def lemmatize_stemming(text):\n",
    "   \n",
    "    token=word_tokenize(text)\n",
    "  \n",
    "    return stemmer.stem(WordNetLemmatizer().lemmatize(text, get_wordnet_pos(nltk.pos_tag(token)[0][1])))\n",
    "def preprocess(text):\n",
    "    result = []\n",
    "    for token in gensim.utils.simple_preprocess(text):\n",
    "        if token not in gensim.parsing.preprocessing.STOPWORDS and len(token) > 3:\n",
    "            result.append(lemmatize_stemming(token))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-20T21:16:50.802529Z",
     "iopub.status.busy": "2022-08-20T21:16:50.801705Z",
     "iopub.status.idle": "2022-08-20T21:16:54.742196Z",
     "shell.execute_reply": "2022-08-20T21:16:54.741141Z",
     "shell.execute_reply.started": "2022-08-20T21:16:50.802474Z"
    }
   },
   "outputs": [],
   "source": [
    "preProcessedText = data[\"title\"].apply(preprocess)\n",
    "titlesWithoutDupes = data[\"title\"].drop_duplicates()\n",
    "titlesWithoutDupes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-20T21:16:54.744495Z",
     "iopub.status.busy": "2022-08-20T21:16:54.744068Z",
     "iopub.status.idle": "2022-08-20T21:16:56.025481Z",
     "shell.execute_reply": "2022-08-20T21:16:56.024306Z",
     "shell.execute_reply.started": "2022-08-20T21:16:54.744404Z"
    }
   },
   "outputs": [],
   "source": [
    "preProcessedText\n",
    "preProcessedTextWithoutComments = titlesWithoutDupes.apply(preprocess)\n",
    "preProcessedTextWithoutComments "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-20T21:16:56.027545Z",
     "iopub.status.busy": "2022-08-20T21:16:56.027174Z",
     "iopub.status.idle": "2022-08-20T21:16:56.036849Z",
     "shell.execute_reply": "2022-08-20T21:16:56.035364Z",
     "shell.execute_reply.started": "2022-08-20T21:16:56.027508Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define helper functions\n",
    "def get_top_n_words(n_top_words, count_vectorizer, text_data):\n",
    "    '''\n",
    "    returns a tuple of the top n words in a sample and their \n",
    "    accompanying counts, given a CountVectorizer object and text sample\n",
    "    '''\n",
    "    vectorized_headlines = count_vectorizer.fit_transform(text_data.values)\n",
    "    vectorized_total = np.sum(vectorized_headlines, axis=0)\n",
    "    word_indices = np.flip(np.argsort(vectorized_total)[0,:], 1)\n",
    "    word_values = np.flip(np.sort(vectorized_total)[0,:],1)\n",
    "    \n",
    "    word_vectors = np.zeros((n_top_words, vectorized_headlines.shape[1]))\n",
    "    for i in range(n_top_words):\n",
    "        word_vectors[i,word_indices[0,i]] = 1\n",
    "\n",
    "    words = [word[0].encode('ascii').decode('utf-8') for \n",
    "             word in count_vectorizer.inverse_transform(word_vectors)]\n",
    "\n",
    "    return (words, word_values[0,:n_top_words].tolist()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-20T21:16:56.039594Z",
     "iopub.status.busy": "2022-08-20T21:16:56.039084Z",
     "iopub.status.idle": "2022-08-20T21:16:56.056865Z",
     "shell.execute_reply": "2022-08-20T21:16:56.055576Z",
     "shell.execute_reply.started": "2022-08-20T21:16:56.039538Z"
    }
   },
   "outputs": [],
   "source": [
    "data = data['title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-20T21:16:56.059879Z",
     "iopub.status.busy": "2022-08-20T21:16:56.059044Z",
     "iopub.status.idle": "2022-08-20T21:16:56.378349Z",
     "shell.execute_reply": "2022-08-20T21:16:56.377501Z",
     "shell.execute_reply.started": "2022-08-20T21:16:56.059824Z"
    }
   },
   "outputs": [],
   "source": [
    "count_vectorizer = CountVectorizer(stop_words='english')\n",
    "words, word_values = get_top_n_words(n_top_words=15,\n",
    "                                     count_vectorizer=count_vectorizer, \n",
    "                                     text_data=data)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(16,8))\n",
    "ax.bar(range(len(words)), word_values);\n",
    "ax.set_xticks(range(len(words)));\n",
    "ax.set_xticklabels(words, rotation='vertical');\n",
    "ax.set_title('Top words in title dataset (excluding stop words)');\n",
    "ax.set_xlabel('Word');\n",
    "ax.set_ylabel('Number of occurences');\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-20T21:16:56.380062Z",
     "iopub.status.busy": "2022-08-20T21:16:56.379618Z",
     "iopub.status.idle": "2022-08-20T21:16:57.683960Z",
     "shell.execute_reply": "2022-08-20T21:16:57.682516Z",
     "shell.execute_reply.started": "2022-08-20T21:16:56.380009Z"
    }
   },
   "outputs": [],
   "source": [
    "tag = [TextBlob(data[i]).pos_tags for i in range(data.shape[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-20T21:16:57.686344Z",
     "iopub.status.busy": "2022-08-20T21:16:57.685881Z",
     "iopub.status.idle": "2022-08-20T21:16:57.704758Z",
     "shell.execute_reply": "2022-08-20T21:16:57.703586Z",
     "shell.execute_reply.started": "2022-08-20T21:16:57.686280Z"
    }
   },
   "outputs": [],
   "source": [
    "tagged_tweet_df = pd.DataFrame({'tags':tag})\n",
    "\n",
    "word_counts = [] \n",
    "pos_counts = {}\n",
    "\n",
    "for tweet in tagged_tweet_df[u'tags']:\n",
    "    word_counts.append(len(tweet))\n",
    "    for tag in tweet:\n",
    "        if tag[1] in pos_counts:\n",
    "            pos_counts[tag[1]] += 1\n",
    "        else:\n",
    "            pos_counts[tag[1]] = 1\n",
    "            \n",
    "print('Total number of words: ', np.sum(word_counts))\n",
    "print('Mean number of words per tweet: ', np.mean(word_counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-20T21:16:57.708044Z",
     "iopub.status.busy": "2022-08-20T21:16:57.707593Z",
     "iopub.status.idle": "2022-08-20T21:16:58.108743Z",
     "shell.execute_reply": "2022-08-20T21:16:58.107567Z",
     "shell.execute_reply.started": "2022-08-20T21:16:57.708005Z"
    }
   },
   "outputs": [],
   "source": [
    "pos_sorted_types = sorted(pos_counts, key=pos_counts.__getitem__, reverse=True)\n",
    "pos_sorted_counts = sorted(pos_counts.values(), reverse=True)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(18,8))\n",
    "ax.bar(range(len(pos_counts)), pos_sorted_counts);\n",
    "ax.set_xticks(range(len(pos_counts)));\n",
    "ax.set_xticklabels(pos_sorted_types);\n",
    "ax.set_title('Part-of-Speech Tagging for title Corpus');\n",
    "ax.set_xlabel('Type of Word');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-20T21:17:35.220208Z",
     "iopub.status.busy": "2022-08-20T21:17:35.219408Z",
     "iopub.status.idle": "2022-08-20T21:17:35.249334Z",
     "shell.execute_reply": "2022-08-20T21:17:35.248300Z",
     "shell.execute_reply.started": "2022-08-20T21:17:35.220164Z"
    }
   },
   "outputs": [],
   "source": [
    "small_count_vectorizer = CountVectorizer(stop_words='english', max_features=40000)\n",
    "small_text_sample = data.sample(n=1602, random_state=0).values\n",
    "\n",
    "print('Text before vectorization: {}'.format(small_text_sample[123]))\n",
    "\n",
    "small_document_term_matrix = small_count_vectorizer.fit_transform(small_text_sample)\n",
    "\n",
    "print('Text after vectorization: \\n{}'.format(small_document_term_matrix[123]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-20T21:17:37.210649Z",
     "iopub.status.busy": "2022-08-20T21:17:37.209957Z",
     "iopub.status.idle": "2022-08-20T21:17:37.216186Z",
     "shell.execute_reply": "2022-08-20T21:17:37.215174Z",
     "shell.execute_reply.started": "2022-08-20T21:17:37.210607Z"
    }
   },
   "outputs": [],
   "source": [
    "n_topics = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-20T21:17:37.831791Z",
     "iopub.status.busy": "2022-08-20T21:17:37.831216Z",
     "iopub.status.idle": "2022-08-20T21:17:37.888044Z",
     "shell.execute_reply": "2022-08-20T21:17:37.886617Z",
     "shell.execute_reply.started": "2022-08-20T21:17:37.831752Z"
    }
   },
   "outputs": [],
   "source": [
    "lsa_model = TruncatedSVD(n_components=n_topics)\n",
    "lsa_topic_matrix = lsa_model.fit_transform(small_document_term_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-20T21:17:38.365102Z",
     "iopub.status.busy": "2022-08-20T21:17:38.364721Z",
     "iopub.status.idle": "2022-08-20T21:17:38.371279Z",
     "shell.execute_reply": "2022-08-20T21:17:38.370240Z",
     "shell.execute_reply.started": "2022-08-20T21:17:38.365069Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_keys(topic_matrix):\n",
    "    '''\n",
    "    returns an integer list of predicted topic \n",
    "    categories for a given topic matrix\n",
    "    '''\n",
    "    keys = topic_matrix.argmax(axis=1).tolist()\n",
    "    return keys\n",
    "\n",
    "def keys_to_counts(keys):\n",
    "    '''\n",
    "    returns a tuple of topic categories and their \n",
    "    accompanying magnitudes for a given list of keys\n",
    "    '''\n",
    "    count_pairs = Counter(keys).items()\n",
    "    categories = [pair[0] for pair in count_pairs]\n",
    "    counts = [pair[1] for pair in count_pairs]\n",
    "    return (categories, counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-20T21:17:38.895346Z",
     "iopub.status.busy": "2022-08-20T21:17:38.894807Z",
     "iopub.status.idle": "2022-08-20T21:17:38.900463Z",
     "shell.execute_reply": "2022-08-20T21:17:38.899441Z",
     "shell.execute_reply.started": "2022-08-20T21:17:38.895309Z"
    }
   },
   "outputs": [],
   "source": [
    "lsa_keys = get_keys(lsa_topic_matrix)\n",
    "lsa_categories, lsa_counts = keys_to_counts(lsa_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-20T21:17:39.362205Z",
     "iopub.status.busy": "2022-08-20T21:17:39.361668Z",
     "iopub.status.idle": "2022-08-20T21:17:39.370723Z",
     "shell.execute_reply": "2022-08-20T21:17:39.369438Z",
     "shell.execute_reply.started": "2022-08-20T21:17:39.362170Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_top_n_words(n, keys, document_term_matrix, count_vectorizer):\n",
    "    '''\n",
    "    returns a list of n_topic strings, where each string contains the n most common \n",
    "    words in a predicted category, in order\n",
    "    '''\n",
    "    top_word_indices = []\n",
    "    for topic in range(n_topics):\n",
    "        temp_vector_sum = 0\n",
    "        for i in range(len(keys)):\n",
    "            if keys[i] == topic:\n",
    "                temp_vector_sum += document_term_matrix[i]\n",
    "        temp_vector_sum = temp_vector_sum.toarray()\n",
    "        top_n_word_indices = np.flip(np.argsort(temp_vector_sum)[0][-n:],0)\n",
    "        top_word_indices.append(top_n_word_indices)   \n",
    "    top_words = []\n",
    "    for topic in top_word_indices:\n",
    "        topic_words = []\n",
    "        for index in topic:\n",
    "            temp_word_vector = np.zeros((1,document_term_matrix.shape[1]))\n",
    "            temp_word_vector[:,index] = 1\n",
    "            the_word = count_vectorizer.inverse_transform(temp_word_vector)[0][0]\n",
    "            topic_words.append(the_word)#.encode('ascii').decode('utf-8'))\n",
    "        top_words.append(\" \".join(topic_words))         \n",
    "    return top_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-20T21:17:39.839167Z",
     "iopub.status.busy": "2022-08-20T21:17:39.838645Z",
     "iopub.status.idle": "2022-08-20T21:17:40.241430Z",
     "shell.execute_reply": "2022-08-20T21:17:40.240460Z",
     "shell.execute_reply.started": "2022-08-20T21:17:39.839131Z"
    }
   },
   "outputs": [],
   "source": [
    "top_n_words_lsa = get_top_n_words(10, lsa_keys, small_document_term_matrix, small_count_vectorizer)\n",
    "\n",
    "for i in range(len(top_n_words_lsa)):\n",
    "    print(\"Topic {}: \".format(i+1), top_n_words_lsa[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-20T21:17:40.278034Z",
     "iopub.status.busy": "2022-08-20T21:17:40.277683Z",
     "iopub.status.idle": "2022-08-20T21:17:40.861507Z",
     "shell.execute_reply": "2022-08-20T21:17:40.860389Z",
     "shell.execute_reply.started": "2022-08-20T21:17:40.278004Z"
    }
   },
   "outputs": [],
   "source": [
    "top_3_words = get_top_n_words(3, lsa_keys, small_document_term_matrix, small_count_vectorizer)\n",
    "labels = ['Topic {}: \\n'.format(i) + top_3_words[i] for i in lsa_categories]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(16,8))\n",
    "ax.bar(lsa_categories, lsa_counts);\n",
    "ax.set_xticks(lsa_categories);\n",
    "ax.set_xticklabels(labels);\n",
    "ax.set_ylabel('Number of title');\n",
    "ax.set_title('LSA topic counts');\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-20T21:17:41.631236Z",
     "iopub.status.busy": "2022-08-20T21:17:41.630831Z",
     "iopub.status.idle": "2022-08-20T21:17:52.003540Z",
     "shell.execute_reply": "2022-08-20T21:17:52.002590Z",
     "shell.execute_reply.started": "2022-08-20T21:17:41.631202Z"
    }
   },
   "outputs": [],
   "source": [
    "tsne_lsa_model = TSNE(n_components=2, perplexity=50, learning_rate=100, \n",
    "                        n_iter=2000, verbose=1, random_state=0, angle=0.75)\n",
    "tsne_lsa_vectors = tsne_lsa_model.fit_transform(lsa_topic_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-20T21:17:52.009338Z",
     "iopub.status.busy": "2022-08-20T21:17:52.007318Z",
     "iopub.status.idle": "2022-08-20T21:17:52.016053Z",
     "shell.execute_reply": "2022-08-20T21:17:52.015037Z",
     "shell.execute_reply.started": "2022-08-20T21:17:52.009265Z"
    }
   },
   "outputs": [],
   "source": [
    "colormap = np.array([\n",
    "    \"#1f77b4\", \"#aec7e8\", \"#ff7f0e\", \"#ffbb78\", \"#2ca02c\",\n",
    "    \"#98df8a\", \"#d62728\", \"#ff9896\", \"#9467bd\", \"#c5b0d5\",\n",
    "    \"#8c564b\", \"#c49c94\", \"#e377c2\", \"#f7b6d2\", \"#7f7f7f\",\n",
    "    \"#c7c7c7\", \"#bcbd22\", \"#dbdb8d\", \"#17becf\", \"#9edae5\" ])\n",
    "colormap = colormap[:n_topics]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-20T21:17:59.952015Z",
     "iopub.status.busy": "2022-08-20T21:17:59.951628Z",
     "iopub.status.idle": "2022-08-20T21:17:59.958497Z",
     "shell.execute_reply": "2022-08-20T21:17:59.957373Z",
     "shell.execute_reply.started": "2022-08-20T21:17:59.951984Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_mean_topic_vectors(keys, two_dim_vectors):\n",
    "    '''\n",
    "    returns a list of centroid vectors from each predicted topic category\n",
    "    '''\n",
    "    mean_topic_vectors = []\n",
    "    for t in range(n_topics):\n",
    "        articles_in_that_topic = []\n",
    "        for i in range(len(keys)):\n",
    "            if keys[i] == t:\n",
    "                articles_in_that_topic.append(two_dim_vectors[i])    \n",
    "        \n",
    "        articles_in_that_topic = np.vstack(articles_in_that_topic)\n",
    "        mean_article_in_that_topic = np.mean(articles_in_that_topic, axis=0)\n",
    "        mean_topic_vectors.append(mean_article_in_that_topic)\n",
    "    return mean_topic_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-20T21:18:00.668555Z",
     "iopub.status.busy": "2022-08-20T21:18:00.668122Z",
     "iopub.status.idle": "2022-08-20T21:18:01.111063Z",
     "shell.execute_reply": "2022-08-20T21:18:01.109979Z",
     "shell.execute_reply.started": "2022-08-20T21:18:00.668519Z"
    }
   },
   "outputs": [],
   "source": [
    "top_3_words_lsa = get_top_n_words(3, lsa_keys, small_document_term_matrix, small_count_vectorizer)\n",
    "lsa_mean_topic_vectors = get_mean_topic_vectors(lsa_keys, tsne_lsa_vectors)\n",
    "\n",
    "plot = figure(title=\"t-SNE Clustering of {} LSA Topics\".format(n_topics), plot_width=700, plot_height=700)\n",
    "plot.scatter(x=tsne_lsa_vectors[:,0], y=tsne_lsa_vectors[:,1], color=colormap[lsa_keys])\n",
    "\n",
    "for t in range(n_topics):\n",
    "    label = Label(x=lsa_mean_topic_vectors[t][0], y=lsa_mean_topic_vectors[t][1], \n",
    "                  text=top_3_words_lsa[t], text_color=colormap[t])\n",
    "    plot.add_layout(label)\n",
    "    \n",
    "show(plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-20T21:18:01.811192Z",
     "iopub.status.busy": "2022-08-20T21:18:01.810537Z",
     "iopub.status.idle": "2022-08-20T21:18:03.330453Z",
     "shell.execute_reply": "2022-08-20T21:18:03.329256Z",
     "shell.execute_reply.started": "2022-08-20T21:18:01.811142Z"
    }
   },
   "outputs": [],
   "source": [
    "lda_model = LatentDirichletAllocation(n_components=n_topics, learning_method='online', \n",
    "                                          random_state=0, verbose=0)\n",
    "lda_topic_matrix = lda_model.fit_transform(small_document_term_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-20T21:18:03.332513Z",
     "iopub.status.busy": "2022-08-20T21:18:03.332071Z",
     "iopub.status.idle": "2022-08-20T21:18:03.337352Z",
     "shell.execute_reply": "2022-08-20T21:18:03.336444Z",
     "shell.execute_reply.started": "2022-08-20T21:18:03.332467Z"
    }
   },
   "outputs": [],
   "source": [
    "lda_keys = get_keys(lda_topic_matrix)\n",
    "lda_categories, lda_counts = keys_to_counts(lda_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-20T21:18:04.378514Z",
     "iopub.status.busy": "2022-08-20T21:18:04.377840Z",
     "iopub.status.idle": "2022-08-20T21:18:04.788382Z",
     "shell.execute_reply": "2022-08-20T21:18:04.787219Z",
     "shell.execute_reply.started": "2022-08-20T21:18:04.378459Z"
    }
   },
   "outputs": [],
   "source": [
    "top_n_words_lda = get_top_n_words(10, lda_keys, small_document_term_matrix, small_count_vectorizer)\n",
    "\n",
    "for i in range(len(top_n_words_lda)):\n",
    "    print(\"Topic {}: \".format(i+1), top_n_words_lda[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-20T21:18:05.231152Z",
     "iopub.status.busy": "2022-08-20T21:18:05.230733Z",
     "iopub.status.idle": "2022-08-20T21:18:05.776986Z",
     "shell.execute_reply": "2022-08-20T21:18:05.775899Z",
     "shell.execute_reply.started": "2022-08-20T21:18:05.231114Z"
    }
   },
   "outputs": [],
   "source": [
    "top_3_words = get_top_n_words(3, lda_keys, small_document_term_matrix, small_count_vectorizer)\n",
    "labels = ['Topic {}: \\n'.format(i) + top_3_words[i] for i in lda_categories]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(16,8))\n",
    "ax.bar(lda_categories, lda_counts);\n",
    "ax.set_xticks(lda_categories);\n",
    "ax.set_xticklabels(labels);\n",
    "ax.set_title('LDA topic counts');\n",
    "ax.set_ylabel('Number of title');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-20T21:18:05.986523Z",
     "iopub.status.busy": "2022-08-20T21:18:05.986117Z",
     "iopub.status.idle": "2022-08-20T21:18:15.140990Z",
     "shell.execute_reply": "2022-08-20T21:18:15.140072Z",
     "shell.execute_reply.started": "2022-08-20T21:18:05.986488Z"
    }
   },
   "outputs": [],
   "source": [
    "tsne_lda_model = TSNE(n_components=2, perplexity=50, learning_rate=100, \n",
    "                        n_iter=2000, verbose=1, random_state=0, angle=0.75)\n",
    "tsne_lda_vectors = tsne_lda_model.fit_transform(lda_topic_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-20T21:18:15.143218Z",
     "iopub.status.busy": "2022-08-20T21:18:15.142588Z",
     "iopub.status.idle": "2022-08-20T21:18:15.765115Z",
     "shell.execute_reply": "2022-08-20T21:18:15.764105Z",
     "shell.execute_reply.started": "2022-08-20T21:18:15.143175Z"
    }
   },
   "outputs": [],
   "source": [
    "top_3_words_lda = get_top_n_words(3, lda_keys, small_document_term_matrix, small_count_vectorizer)\n",
    "lda_mean_topic_vectors = get_mean_topic_vectors(lda_keys, tsne_lda_vectors)\n",
    "\n",
    "plot = figure(title=\"t-SNE Clustering of {} LDA Topics\".format(n_topics), plot_width=700, plot_height=700)\n",
    "plot.scatter(x=tsne_lda_vectors[:,0], y=tsne_lda_vectors[:,1], color=colormap[lda_keys])\n",
    "\n",
    "for t in range(n_topics):\n",
    "    label = Label(x=lda_mean_topic_vectors[t][0], y=lda_mean_topic_vectors[t][1], \n",
    "                  text=top_3_words_lda[t], text_color=colormap[t])\n",
    "    plot.add_layout(label)\n",
    "\n",
    "show(plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-20T21:18:15.767215Z",
     "iopub.status.busy": "2022-08-20T21:18:15.766890Z",
     "iopub.status.idle": "2022-08-20T21:18:18.947643Z",
     "shell.execute_reply": "2022-08-20T21:18:18.946701Z",
     "shell.execute_reply.started": "2022-08-20T21:18:15.767182Z"
    }
   },
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim import corpora\n",
    "bigram = gensim.models.Phrases(preProcessedTextWithoutComments , min_count=5, threshold=100) \n",
    "#trigram = gensim.models.Phrases(bigram[document_cleaned], threshold=100)\n",
    "bigram_mod = gensim.models.phrases.Phraser(bigram)\n",
    "def make_bigrams(texts):\n",
    "    return [bigram_mod[doc] for doc in texts]\n",
    "data_words_bigrams = make_bigrams(preProcessedTextWithoutComments )# Creating the term dictionary of our courpus, \n",
    "# where every unique term is assigned an index. \n",
    "dictionary = corpora.Dictionary(data_words_bigrams)# Converting list of documents (corpus) \n",
    "# into Document Term Matrix using dictionary prepared above.\n",
    "doc_term_matrix = [dictionary.doc2bow(text) for text in data_words_bigrams]# Build the LDA model\n",
    "from gensim.models import LdaModel\n",
    "lda_model = LdaModel(corpus=doc_term_matrix,id2word=dictionary,num_topics=5,random_state=100,\n",
    "                     passes=10,alpha=0.31,eta=0.9099999999999999)\n",
    "lda_model.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-20T21:18:18.949695Z",
     "iopub.status.busy": "2022-08-20T21:18:18.949073Z",
     "iopub.status.idle": "2022-08-20T21:18:19.141013Z",
     "shell.execute_reply": "2022-08-20T21:18:19.139904Z",
     "shell.execute_reply.started": "2022-08-20T21:18:18.949651Z"
    }
   },
   "outputs": [],
   "source": [
    "lda_df = lda_model.get_document_topics(doc_term_matrix,minimum_probability=0)\n",
    "lda_df = pd.DataFrame(list(lda_df))\n",
    "num_topics = lda_model.num_topics\n",
    "lda_df.columns = ['Topic'+str(i) for i in range(num_topics)]\n",
    "for i in range(len(lda_df.columns)):\n",
    "    lda_df.iloc[:,i]=lda_df.iloc[:,i].apply(lambda x: x[1])\n",
    "lda_df['Automated_topic_id'] =lda_df.apply(lambda x: np.argmax(x),axis=1)\n",
    "lda_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-20T21:18:19.535121Z",
     "iopub.status.busy": "2022-08-20T21:18:19.534717Z",
     "iopub.status.idle": "2022-08-20T21:18:20.045621Z",
     "shell.execute_reply": "2022-08-20T21:18:20.044376Z",
     "shell.execute_reply.started": "2022-08-20T21:18:19.535088Z"
    }
   },
   "outputs": [],
   "source": [
    "# Compute Perplexity, a measure of how good the model is. lower the better.\n",
    "from gensim.models import CoherenceModel\n",
    "print('\\nPerplexity: ', lda_model.log_perplexity(doc_term_matrix))# Compute Coherence Score for lda model\n",
    "coherence_model_lda = CoherenceModel(model=lda_model, texts=data_words_bigrams, dictionary=dictionary, coherence='c_v')\n",
    "coherence_lda_c_v = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score using c_v: ', coherence_lda_c_v)# Compute Coherence Score for lda model\n",
    "coherence_model_lda = CoherenceModel(model=lda_model, texts=data_words_bigrams, dictionary=dictionary, coherence='u_mass')\n",
    "coherence_lda_u_mass = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score using u_mass: ', coherence_lda_u_mass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-20T21:18:20.417061Z",
     "iopub.status.busy": "2022-08-20T21:18:20.416688Z",
     "iopub.status.idle": "2022-08-20T21:18:23.346271Z",
     "shell.execute_reply": "2022-08-20T21:18:23.344871Z",
     "shell.execute_reply.started": "2022-08-20T21:18:20.417025Z"
    }
   },
   "outputs": [],
   "source": [
    "import pyLDAvis\n",
    "import pyLDAvis.gensim_models as gensimvis\n",
    "pyLDAvis.enable_notebook()\n",
    "\n",
    "# feed the LDA model into the pyLDAvis instance\n",
    "lda_viz = gensimvis.prepare(lda_model, doc_term_matrix, dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-20T21:18:23.348891Z",
     "iopub.status.busy": "2022-08-20T21:18:23.348416Z",
     "iopub.status.idle": "2022-08-20T21:18:23.378752Z",
     "shell.execute_reply": "2022-08-20T21:18:23.377893Z",
     "shell.execute_reply.started": "2022-08-20T21:18:23.348849Z"
    }
   },
   "outputs": [],
   "source": [
    "lda_viz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-20T21:18:23.381233Z",
     "iopub.status.busy": "2022-08-20T21:18:23.380641Z",
     "iopub.status.idle": "2022-08-20T21:18:23.474944Z",
     "shell.execute_reply": "2022-08-20T21:18:23.473266Z",
     "shell.execute_reply.started": "2022-08-20T21:18:23.381190Z"
    }
   },
   "outputs": [],
   "source": [
    "from gensim.models import LsiModel\n",
    "lsi_model = LsiModel(corpus=doc_term_matrix, num_topics=4, id2word=dictionary)\n",
    "lsi_model.print_topics(num_topics=10,num_words=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-20T21:18:23.487731Z",
     "iopub.status.busy": "2022-08-20T21:18:23.482860Z",
     "iopub.status.idle": "2022-08-20T21:18:23.813366Z",
     "shell.execute_reply": "2022-08-20T21:18:23.811162Z",
     "shell.execute_reply.started": "2022-08-20T21:18:23.487629Z"
    }
   },
   "outputs": [],
   "source": [
    "# Compute Coherence Score for llsi model\n",
    "coherence_model_lsi = CoherenceModel(model=lsi_model, texts=data_words_bigrams, dictionary=dictionary, coherence='c_v')\n",
    "coherence_lsi_c_v = coherence_model_lsi.get_coherence()\n",
    "print('\\nCoherence Score for LSI using c_v: ', coherence_lsi_c_v)# Compute Coherence Score for llsi model\n",
    "coherence_model_lsi = CoherenceModel(model=lsi_model, texts=data_words_bigrams, dictionary=dictionary, coherence='u_mass')\n",
    "coherence_lsi_u_mass = coherence_model_lsi.get_coherence()\n",
    "print('\\nCoherence Score for LSI using u_mass: ', coherence_lsi_u_mass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-20T21:18:24.132568Z",
     "iopub.status.busy": "2022-08-20T21:18:24.130122Z",
     "iopub.status.idle": "2022-08-20T21:18:24.564738Z",
     "shell.execute_reply": "2022-08-20T21:18:24.563343Z",
     "shell.execute_reply.started": "2022-08-20T21:18:24.132510Z"
    }
   },
   "outputs": [],
   "source": [
    "from gensim.models import CoherenceModel\n",
    "lda_topics = [[word for word, prob in topic] for topicid, topic in lda_model.show_topics(formatted=False)]\n",
    "lsi_topics = [[word for word, prob in topic] for topicid, topic in lsi_model.show_topics(formatted=False)]\n",
    "lsi_coherence = CoherenceModel(topics=lsi_topics, texts=data_words_bigrams, dictionary=dictionary, window_size=10).get_coherence()\n",
    "lda_coherence = CoherenceModel(topics=lda_topics, texts=data_words_bigrams, dictionary=dictionary, window_size=10).get_coherence()\n",
    "import numpy as np\n",
    "def topic_model_graph(coherences, indices):\n",
    "    \"\"\"\n",
    "    Function to plot bar graph.\n",
    "    \n",
    "    coherences: list of coherence values\n",
    "    indices: Indices to be used to mark bars. Length of this and coherences should be equal.\n",
    "    \"\"\"\n",
    "    assert len(coherences) == len(indices)\n",
    "    n = len(coherences)\n",
    "    x = np.arange(n)\n",
    "    plt.bar(x, coherences, width=0.2, tick_label=indices, align='center')\n",
    "    plt.xlabel('Models')\n",
    "    plt.ylabel('Coherence Value')\n",
    "topic_model_graph([lsi_coherence, lda_coherence],\n",
    "                   ['LSI',  'LDA'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
